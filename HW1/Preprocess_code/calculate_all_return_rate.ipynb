{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[1]:\n",
    "from selenium import webdriver\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rate(data,etf_name,return_list) :\n",
    "    for i in range(len(data[etf_name])-1) :\n",
    "        return_list.append((data[etf_name][i+1] - data[etf_name][i]) / data[etf_name][i])\n",
    "    return return_list\n",
    "\n",
    "def load_data (etfcsvpath) :\n",
    "    etfdata = pd.read_csv(etfcsvpath)\n",
    "    return etfdata         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n",
      "已新增資料夾\n"
     ]
    }
   ],
   "source": [
    "download_path1 = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\merge_data\\\\\"\n",
    "file_path_list1 = []\n",
    "file_name1 =[]\n",
    "for file in os.listdir(download_path1):\n",
    "    file_path_list1.append(os.path.join(download_path1, file))\n",
    "    file_name1.append(file)\n",
    "\n",
    "name_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\dataset\\\\\"\n",
    "name_path_list = []\n",
    "file_name_etf =[]\n",
    "for file in os.listdir(name_path):\n",
    "    name_path_list.append(os.path.join(name_path, file))\n",
    "    file_name_etf.append(file[:-4])    \n",
    "\n",
    "    \n",
    "###  define the datetime we want\n",
    "\n",
    "start = dt.datetime(2013,12,1)\n",
    "end = dt.datetime(2019,3,12)\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for file in file_path_list1 :\n",
    "    download_path = file\n",
    "    file_path_list = []\n",
    "    file_name =[]\n",
    "    for file in os.listdir(download_path):\n",
    "        file_path_list.append(os.path.join(download_path, file))\n",
    "        file_name.append(file)\n",
    "    \n",
    "     \n",
    "    save_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\2014to2018RE_data_new\\\\{}\\\\\".format(file_name_etf[count])\n",
    "    if os.path.exists(save_path) and os.path.isdir(save_path):\n",
    "            print(save_path + '資料夾已存在')\n",
    "    else:\n",
    "            os.makedirs(save_path)\n",
    "            print('已新增資料夾')\n",
    "            \n",
    "           \n",
    "    ### filter data and run through the function \n",
    "    \n",
    "    \n",
    "    data = load_data(file_path_list[0])\n",
    "    \n",
    "        \n",
    "    listtime = data['Date']\n",
    "    listdate = []\n",
    "    \n",
    "    ### turn str into datetime type\n",
    "    \n",
    "    for time in listtime :\n",
    "        try :\n",
    "            listdate.append(dt.datetime.strptime(time,'%Y-%m-%d'))\n",
    "        except:\n",
    "            listdate.append(dt.datetime.strptime(time,'%Y/%m/%d'))\n",
    "    data['Date'] = listdate    ### trun it into datetime\n",
    "    \n",
    "    data = data.iloc[:,1:] \n",
    "    ### filter all data on the dateline\n",
    "\n",
    "    filter = (data['Date'] <= end )\n",
    "    clean_data = data[filter]\n",
    "    filter = (clean_data['Date'] >= start)\n",
    "    clean_data = clean_data[filter]\n",
    "    clean_data.reset_index(inplace = True)            \n",
    "    \n",
    "    ### clean data\n",
    "    \n",
    "    etf_list =  clean_data.columns.to_list()\n",
    "    date_list = clean_data['Date'].iloc[:-1]  ### change here !!!!\n",
    "    date_list = date_list.reset_index()\n",
    "    date_list = date_list.iloc[:,1]\n",
    "    etf_list = etf_list[2:]\n",
    "        \n",
    "    \n",
    "    ### calculate the return rate \n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for name in etf_list :\n",
    "        lis = []\n",
    "        return_list =return_rate(clean_data,name,lis)\n",
    "        df[name] = return_list\n",
    "    df = pd.concat([date_list,df],axis=1)\n",
    "    ### save the data\n",
    "    \n",
    "    df.to_csv(save_path+file_name_etf[count]+'_return'+'.csv')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

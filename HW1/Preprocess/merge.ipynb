{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path, PureWindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取資料之function\n",
    "\n",
    "def load_data (etfcsvpath) :\n",
    "    etfdata = pd.read_csv(etfcsvpath)\n",
    "    return etfdata \n",
    "\n",
    "# 找出時間最長的etf_function\n",
    "\n",
    "def find_longer (path): \n",
    "    df = pd.read_csv(path)\n",
    "    lenlist.append(len(df))\n",
    "    maxlen =max(lenlist)\n",
    "    return maxlen\n",
    "\n",
    "# 找出最長時間etf的名稱\n",
    "\n",
    "def find_long_name (maxlen,path) :\n",
    "    df = pd.read_csv(path)\n",
    "    if len(df) == maxlen :\n",
    "        lonestpath.append(path)\n",
    "    return lonestpath\n",
    "\n",
    "# 將其所以符合的etf合併成一個dataframe\n",
    "\n",
    "def merge (first_etf,path) :\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['Date','Adj Close']]\n",
    "    merge_data = first_etf.merge(df,how='outer',on = 'Date')\n",
    "    return merge_data\n",
    "\n",
    "# 將合併dataframe重新命名並且存取至特定路徑\n",
    "\n",
    "def name_all_columns(first_etf_name,merge_data,savepath,filename) :\n",
    "    columnsname = ['Date',first_etf_name]\n",
    "    for name in ETF_name :\n",
    "        columnsname.append(name)\n",
    "    merge_data.columns = columnsname\n",
    "    mergealldf = merge_data.drop(merge_data.iloc[:,1:2],axis=1)\n",
    "    mergealldf.to_csv(savepath+filename+'.csv')\n",
    "    return mergealldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Alternatives ETF List (35)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Broad Asia ETF List (44)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Commodity ETF List (125)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Consumer Discretionary Equity ETF List (31)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Consumer Staples Equity ETF List (26)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Crude Oil ETF List (22)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Currency ETF List (36)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Asia Pacific ETF List (108)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Markets ETF List 1 (100)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Markets ETF List 2 (100)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Markets ETF List 3 (93)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Emerging Asia Pacific ETF List (114)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Emerging Markets ETF List (79)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Energy Equity ETF List (80)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Financials Equity ETF List (51)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Global ETF List (72)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Gold ETF List (17)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Healthcare Equity ETF List (49)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Industrials Equity ETF List (37)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Investment Grade Corporate ETF List (50)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Junk ETF List (43)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Materials Equity ETF List (62)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Municipal Bond ETF List (29)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Preferred Stock ETF List (12)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Real Estate ETF List (48)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Target Maturity Date Corporate Bond ETF List (24)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Technology Equity ETF List (75)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Telecom Equity ETF List (10)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Total Bond Market ETF List (82)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Treasuries ETF List (51)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Utilities Equity ETF List (24)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Volatility ETF List (18)\\資料夾已存在\n"
     ]
    }
   ],
   "source": [
    "# 抓取檔案位置並且存成list方便後續使用\n",
    "\n",
    "download_path1 = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\filter\\\\\"\n",
    "file_path_list1 = []\n",
    "file_name1 =[]\n",
    "for file in os.listdir(download_path1):\n",
    "    file_path_list1.append(os.path.join(download_path1, file))\n",
    "    file_name1.append(file)\n",
    "    \n",
    "# 此為分成不同group的etf名稱 抓取是為了最後合併的時候命名\n",
    "    \n",
    "name_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\dataset\\\\\"\n",
    "name_path_list = []\n",
    "file_name_etf =[]\n",
    "for file in os.listdir(name_path):\n",
    "    name_path_list.append(os.path.join(name_path, file))\n",
    "    file_name_etf.append(file[:-4])    \n",
    "\n",
    "\n",
    "count = 0    \n",
    "\n",
    "# Loop各個file下的各支ETF\n",
    "\n",
    "for file in file_path_list1 :\n",
    "    download_path = file\n",
    "    file_path_list = []\n",
    "    file_name =[]\n",
    "    for file in os.listdir(download_path):\n",
    "        file_path_list.append(os.path.join(download_path, file))\n",
    "        file_name.append(file)\n",
    "    \n",
    "    # 定義出SAVE的路徑 (名稱取決前面ETF_LIST_GROUP)\n",
    "    \n",
    "    save_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\merge_data\\\\{}\\\\\".format(file_name_etf[count])\n",
    "    if os.path.exists(save_path) and os.path.isdir(save_path):\n",
    "            print(save_path + '資料夾已存在')\n",
    "    else:\n",
    "            os.makedirs(save_path)\n",
    "            print('已新增資料夾')\n",
    "            \n",
    "            \n",
    "            \n",
    "    #########  以下為套用上面的 Function過程 ############\n",
    "    \n",
    "    # 先找出每個group中時間最長的etf   =====>  再抓取其名稱   =====>   再將其名稱當作合併的第一個dataFrame   =====>\n",
    "    \n",
    "    # 原因是因為Python中合併的一些限制 所以必須將時間軸最長的ETF放最前面合併  =====> 之後再合併並且去除當作開頭的ETF_columns \n",
    "    \n",
    "    # 最後將其存取成對應Group_file即完成\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### ps  :   其中count用途只是用來loop etf_group名稱而設定\n",
    "    \n",
    "    lenlist = []\n",
    "    lonestpath = []\n",
    "    for path in file_path_list :\n",
    "        maxlen = find_longer(path)\n",
    "    for path in file_path_list :\n",
    "        lonestpath = find_long_name(maxlen,path)\n",
    "        \n",
    "        \n",
    "        \n",
    "    ETF_name = []\n",
    "\n",
    "    for name in file_name :\n",
    "        ETF_name.append(name[:-4])\n",
    "    df = pd.read_csv(lonestpath[0])\n",
    "    first_etf = df[['Date','Adj Close']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for path in file_path_list :\n",
    "    \n",
    "        etfdata  = load_data(path)\n",
    "    \n",
    "        first_etf = merge(first_etf,path)\n",
    "\n",
    "    name_all_columns(lonestpath[0][-8:-1],first_etf,save_path,file_name_etf[count]+'_merge')\n",
    "    \n",
    "    count +=1  #<=======  為了其etf_name_list設定"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

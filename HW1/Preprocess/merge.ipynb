{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path, PureWindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (etfcsvpath) :\n",
    "    etfdata = pd.read_csv(etfcsvpath)\n",
    "    return etfdata \n",
    "\n",
    "\n",
    "def find_longer (path): \n",
    "    df = pd.read_csv(path)\n",
    "    lenlist.append(len(df))\n",
    "    maxlen =max(lenlist)\n",
    "    return maxlen\n",
    "\n",
    "def find_long_name (maxlen,path) :\n",
    "    df = pd.read_csv(path)\n",
    "    if len(df) == maxlen :\n",
    "        lonestpath.append(path)\n",
    "    return lonestpath\n",
    "\n",
    "def merge (first_etf,path) :\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['Date','Adj Close']]\n",
    "    merge_data = first_etf.merge(df,how='outer',on = 'Date')\n",
    "    return merge_data\n",
    "\n",
    "def name_all_columns(first_etf_name,merge_data,savepath,filename) :\n",
    "    columnsname = ['Date',first_etf_name]\n",
    "    for name in ETF_name :\n",
    "        columnsname.append(name)\n",
    "    merge_data.columns = columnsname\n",
    "    mergealldf = merge_data.drop(merge_data.iloc[:,1:2],axis=1)\n",
    "    mergealldf.to_csv(savepath+filename+'.csv')\n",
    "    return mergealldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Alternatives ETF List (35)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Broad Asia ETF List (44)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Commodity ETF List (125)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Consumer Discretionary Equity ETF List (31)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Consumer Staples Equity ETF List (26)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Crude Oil ETF List (22)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Currency ETF List (36)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Asia Pacific ETF List (108)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Markets ETF List 1 (100)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Markets ETF List 2 (100)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Developed Markets ETF List 3 (93)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Emerging Asia Pacific ETF List (114)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Emerging Markets ETF List (79)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Energy Equity ETF List (80)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Financials Equity ETF List (51)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Global ETF List (72)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Gold ETF List (17)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Healthcare Equity ETF List (49)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Industrials Equity ETF List (37)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Investment Grade Corporate ETF List (50)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Junk ETF List (43)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Materials Equity ETF List (62)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Municipal Bond ETF List (29)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Preferred Stock ETF List (12)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Real Estate ETF List (48)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Target Maturity Date Corporate Bond ETF List (24)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Technology Equity ETF List (75)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Telecom Equity ETF List (10)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Total Bond Market ETF List (82)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Treasuries ETF List (51)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Utilities Equity ETF List (24)\\資料夾已存在\n",
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\merge_data\\Volatility ETF List (18)\\資料夾已存在\n"
     ]
    }
   ],
   "source": [
    "download_path1 = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\filter\\\\\"\n",
    "file_path_list1 = []\n",
    "file_name1 =[]\n",
    "for file in os.listdir(download_path1):\n",
    "    file_path_list1.append(os.path.join(download_path1, file))\n",
    "    file_name1.append(file)\n",
    "\n",
    "name_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\dataset\\\\\"\n",
    "name_path_list = []\n",
    "file_name_etf =[]\n",
    "for file in os.listdir(name_path):\n",
    "    file_path_list.append(os.path.join(name_path, file))\n",
    "    file_name_etf.append(file[:-4])    \n",
    "\n",
    "\n",
    "count = 0    \n",
    "\n",
    "for file in file_path_list1 :\n",
    "    download_path = file\n",
    "    file_path_list = []\n",
    "    file_name =[]\n",
    "    for file in os.listdir(download_path):\n",
    "        file_path_list.append(os.path.join(download_path, file))\n",
    "        file_name.append(file)\n",
    "    \n",
    "    \n",
    "    save_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\merge_data\\\\{}\\\\\".format(file_name_etf[count])\n",
    "    if os.path.exists(save_path) and os.path.isdir(save_path):\n",
    "            print(save_path + '資料夾已存在')\n",
    "    else:\n",
    "            os.makedirs(save_path)\n",
    "            print('已新增資料夾')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    lenlist = []\n",
    "    lonestpath = []\n",
    "    for path in file_path_list :\n",
    "        maxlen = find_longer(path)\n",
    "    for path in file_path_list :\n",
    "        lonestpath = find_long_name(maxlen,path)\n",
    "        \n",
    "        \n",
    "        \n",
    "    ETF_name = []\n",
    "\n",
    "    for name in file_name :\n",
    "        ETF_name.append(name[:-4])\n",
    "    df = pd.read_csv(lonestpath[0])\n",
    "    first_etf = df[['Date','Adj Close']]\n",
    "    \n",
    "    \n",
    "    \n",
    "    for path in file_path_list :\n",
    "    \n",
    "        etfdata  = load_data(path)\n",
    "    \n",
    "        first_etf = merge(first_etf,path)\n",
    "\n",
    "    name_all_columns(lonestpath[0][-8:-1],first_etf,save_path,file_name_etf[count]+'_merge')\n",
    "    \n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\dataset\\\\Alternatives ETF List (35).csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\github\\HW1--data-mining\\HW1\\ETF_data_set\\dataset\\Alternatives ETF List\\資料夾已存在\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "download_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\dataset\\\\Preprocessfilter Alternatives ETF List (35).csv\\\\\"\n",
    "file_path_list = []\n",
    "file_name =[]\n",
    "for file in os.listdir(download_path):\n",
    "    file_path_list.append(os.path.join(download_path, file))\n",
    "    file_name.append(file)\n",
    "    \n",
    "    \n",
    "save_path = \"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\HW1\\\\ETF_data_set\\\\dataset\\\\Alternatives ETF List\\\\\"\n",
    "if os.path.exists(save_path) and os.path.isdir(save_path):\n",
    "        print(save_path + '資料夾已存在')\n",
    "else:\n",
    "        os.makedirs(save_path)\n",
    "        print('已新增資料夾')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenlist = []\n",
    "lonestpath = []\n",
    "for path in file_path_list :\n",
    "    maxlen = find_longer(path)\n",
    "for path in file_path_list :\n",
    "    lonestpath = find_long_name(maxlen,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF_name = []\n",
    "\n",
    "for name in file_name :\n",
    "    ETF_name.append(name[:-4])\n",
    "df = pd.read_csv(lonestpath[0])\n",
    "first_etf = df[['Date','Adj Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in file_path_list :\n",
    "    \n",
    "    etfdata  = load_data(path)\n",
    "    \n",
    "    first_etf = merge(first_etf,path)\n",
    "\n",
    "    name_all_columns(lonestpath[0][-8:-1],first_etf,save_path,'test')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

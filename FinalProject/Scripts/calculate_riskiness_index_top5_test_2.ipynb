{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 列舉所有資產的riskiness r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "from pandas import Series,DataFrame\n",
    "from scipy.optimize import fsolve\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy  as  np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 無風險利率\n",
    "* 我們須扣除無風險利率，得到超額報酬率以計算Riskiness r\n",
    "* 目前使用LIBOR [1個月利率](https://www.global-rates.com/interest-rates/libor/american-dollar/usd-libor-interest-rate-overnight.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfrate = 2.45785 / 12 /100\n",
    "rfrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 關於超額報酬的數量級:\n",
    "* 將要帶入公式的數值調整到介在0-100間，目的是為了讓大部分的Riskiness r介在0-100間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x,arr_returns):\n",
    "    return sum( np.exp(-1*arr_returns/x) ) - len(arr_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_riskiness_r(guess , arr_returns):\n",
    "    while (guess<1000):\n",
    "        risk2 = fsolve(f1,guess,arr_returns)  #引用函數f1\n",
    "        if risk2[0] != guess:\n",
    "            break\n",
    "        guess = guess*10\n",
    "    return risk2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算Riskiness R，並依照R值排序，傳回前十名的ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5_etf(df):\n",
    "    global rfrate\n",
    "    \n",
    "    etf_list = list(df.columns)\n",
    "    \n",
    "    # 計算每支ETF的riskiness r\n",
    "    etf_dic = {}\n",
    "    for etf_name in etf_list:\n",
    "        arr_returns = df[etf_name] - rfrate  \n",
    "        guess = 10**(-5)\n",
    "        #### 列出細項\n",
    "        #print('%s指標值:  %f' %(etf_name,risk2[0]) )\n",
    "        etf_dic[etf_name] = get_riskiness_r(guess,arr_returns)\n",
    "    \n",
    "    # ETF依照riskiness r排序\n",
    "    sorted_x = sorted(etf_dic.items(), key=lambda kv: kv[1])\n",
    "    #sorted_reversed_x = list(reversed(sorted_x))\n",
    "    \n",
    "    # 取前5名\n",
    "    top5 = sorted_x[:5]\n",
    "    \n",
    "    # 取前5的ETF名稱\n",
    "    etf_top5 = [etf[0] for etf in top5]\n",
    "    \n",
    "    #前5的平均\n",
    "    top5_average = df[etf_top5].mean(axis=1)\n",
    "    \n",
    "    return etf_top5 , top5_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取全部ETF資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_months(data_path):\n",
    "    subdir = os.listdir(data_path)[0] #取第一個group的csv檔\n",
    "    file_path = data_path + subdir + '/' + subdir + '_return.csv'\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        total_rows = df.shape[0]\n",
    "        return total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../2014to2018RE_data/'\n",
    "# 以程式取得資料總筆數\n",
    "total_data = get_total_months(data_path)\n",
    "# 或是寫死都可\n",
    "#total_data = 61\n",
    "# 指定用來計算指標的資料個數\n",
    "window_size = 30\n",
    "rolling_times = total_data - window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(rolling_times):\n",
    "    print('=== Rolling #',i+1,'===')\n",
    "    allgroup_top5_return = DataFrame()\n",
    "    allgroup_top5_dict = dict()\n",
    "    for subdir in os.listdir(data_path):\n",
    "        subdir_path = os.path.join(data_path, subdir)\n",
    "        if os.path.exists(subdir_path) and os.path.isdir(subdir_path):\n",
    "            file = subdir + '_return.csv'\n",
    "            file_path = os.path.join(subdir_path, file)\n",
    "            if os.path.isfile(file_path):\n",
    "                df = pd.read_csv(file_path)\n",
    "                df = df.iloc[i:i+30,2:]\n",
    "                # 提出[前10名的名稱,前10名的平均各期報酬]\n",
    "                [ top5_etf,allgroup_top5_return[subdir] ] = get_top5_etf(df)\n",
    "                print('Group:',subdir)\n",
    "                print('Top5:',top5_etf)\n",
    "                print('================')\n",
    "                allgroup_top5_dict[subdir] = top5_etf\n",
    "                df = pd.read_csv(file_path)\n",
    "                etf_date = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allgroup_top5_return = pd.concat([etf_date,allgroup_top5_return],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allgroup_top5_return.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將allgroup_top5 先存取成CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allgroup_top5_return.to_csv(\"allgroup_top5_return_new.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 再次計算Riskiness R，並依照R值排序，傳回前五名的Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5_Group(data_file):\n",
    "\n",
    "    df1 = pd.read_csv(data_file)\n",
    "    etf_list1 = list(df1.columns)[2:] #<----------------------------------------------加上日期\n",
    "    df1 = df1.iloc[:,2:]\n",
    "\n",
    "    etf_dic1 = {}\n",
    "    for etf_name in etf_list1:\n",
    "        # 過濾平均值正負\n",
    "        #if df[etf_name].mean(axis=0) < 0:\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        #-------------------------------------------------------------------------------\n",
    "        \n",
    "        #同上要加上時間\n",
    "        \n",
    "        \n",
    "        arr_returns1 = df1[etf_name] - rfrate\n",
    "        #arr_returns = arr_returns*1000      #調整數量級\n",
    "        \n",
    "        \n",
    "        \n",
    "        #---------------------------------------------------------------------------------\n",
    "        \n",
    "        guess1 = 10**(-5)\n",
    "        #### 列出細項\n",
    "        #print('%s指標值:  %f' %(etf_name,risk2[0]) )\n",
    "        etf_dic1[etf_name] = get_riskiness_r(guess1,arr_returns1)\n",
    "    \n",
    "    \n",
    "    sorted_x1 = sorted(etf_dic1.items(), key=lambda kv: kv[1])\n",
    "        #sorted_reversed_x = list(reversed(sorted_x))\n",
    "    \n",
    "    # 取前5名\n",
    "    top5 = sorted_x1[:5]\n",
    "        # top5 = sorted_reversed_x[:5]\n",
    "    #print(top5)\n",
    "    \n",
    "    # 取前5的ETF名稱\n",
    "    etf_top5 = [etf[0] for etf in top5]\n",
    "\n",
    "    df2 = df1[etf_top5]\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(x):\n",
    "    guess  = 10**(-5)\n",
    "    while (guess<1000):\n",
    "        risk2 = fsolve(f1,guess,x)  #引用函數f1\n",
    "        if risk2[0] != guess:\n",
    "            break\n",
    "        guess = guess*10\n",
    "    return risk2[0]\n",
    "    #return np.std(x)\n",
    "\n",
    "def sumrisk(weight,all_return):\n",
    "    w = weight\n",
    "    a = all_return\n",
    "    v = 0\n",
    "    for i in range(len(w)):\n",
    "        v = v + w[i]*risk(w[i]*(all_return.iloc[:,i]))\n",
    "    return v\n",
    "\n",
    "def penalty(w):\n",
    "    if min(w)<0 or max(w)>1:\n",
    "        return 100000\n",
    "    else:\n",
    "        return 0\n",
    "def portretmean(weight,all_return):\n",
    "    w = weight\n",
    "    a = all_return\n",
    "    return np.mean(np.dot(np.array(all_return),np.array(weight)))    \n",
    "\n",
    "def bestweight(w):\n",
    "    r = []\n",
    "    r.append(penalty(w)+np.abs(sum(w)-1))\n",
    "    for i in range(len(w)-1):\n",
    "        v =  np.abs( risk(w[i]*(all_return.iloc[:,i]))/ sumrisk(w,all_return)  \\\n",
    "            - (np.mean(all_return.iloc[:,i])-rfrate)/(portretmean(w,all_return)-rfrate) ) \\\n",
    "            + np.abs( risk(w[i+1]*(all_return.iloc[:,i+1]))/ sumrisk(w,all_return)  \\\n",
    "            - (np.mean(all_return.iloc[:,i+1])-rfrate)/(portretmean(w,all_return)-rfrate))\n",
    "        r.append(v) \n",
    "    print('權重:',w,'誤差值:',v+penalty(w)+np.abs(sum(w)-1))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fourdrop(x):\n",
    "    a = []\n",
    "    for i in range(len(x)):\n",
    "        a.append(round(sum(x[i]),3))\n",
    "    return a\n",
    "x = np.array(allgroup_top5_return.iloc[:,[0]])\n",
    "x = fourdrop(x)\n",
    "y = np.array(allgroup_top5_return.iloc[:,[1]])\n",
    "y = fourdrop(y)\n",
    "all_return = pd.DataFrame([x,y]).T\n",
    "all_return = all_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-0.01,0,0.0258])\n",
    "y = np.array([-0.05,0,0.134])\n",
    "all_return = pd.DataFrame([x,y]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 依次計算32組的權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = list(range(0, 32))\n",
    "all_return = allgroup_top10_return.iloc[:,a]\n",
    "n = all_return.shape[1]\n",
    "#weight = [0.4,0.6]\n",
    "weight = [1/n]*n\n",
    "r2 = fsolve(bestweight, weight)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算出group中 前五名的權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = get_top5_Group(\"C:\\\\Users\\\\USER\\\\github\\\\HW1--data-mining\\\\FinalProject\\\\Scripts\\\\allgroup_top5_return_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(0, 5))\n",
    "all_return = df2.iloc[:,a]\n",
    "n = all_return.shape[1]\n",
    "#weight = [0.4,0.6]\n",
    "weight = [1/n]*n\n",
    "r2 = fsolve(bestweight, weight)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir in os.listdir(data_path):\n",
    "    subdir_path = os.path.join(data_path, subdir)\n",
    "    if os.path.exists(subdir_path) and os.path.isdir(subdir_path):\n",
    "        file = subdir + '_return.csv'\n",
    "        file_path = os.path.join(subdir_path, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
